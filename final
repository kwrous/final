{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12211323,"sourceType":"datasetVersion","datasetId":7691117}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n本实验包含三种方法的实现和对比：\n1. 原版 NeRF\n2. NeRF 加速技术（TensoRF）\n3. 3D Gaussian Splatting\n\n## 目录\n1. [环境配置](#环境配置)\n2. [数据准备](#数据准备)\n3. [模型实现](#模型实现)\n4. [训练与评估](#训练与评估)\n5. [结果分析](#结果分析)","metadata":{"_uuid":"b43992de-0759-4d21-ae6f-0480b0517aff","_cell_guid":"6ceb62f5-bf89-4f5f-bea5-c621c3882fe7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"\n首先配置必要的环境和依赖。","metadata":{"_uuid":"fd269f00-2b73-45a6-976b-c819683c510c","_cell_guid":"66ff20e9-0b00-4fc1-a7d4-4baa849c4fdb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import os\nimport subprocess\nfrom pathlib import Path\n\n# 创建工作目录\nbase_dir = Path('/kaggle/working')\nos.makedirs(base_dir, exist_ok=True)\nos.chdir(base_dir)\n\n# 克隆必要的仓库\nrepos = {\n    'TensoRF': 'https://github.com/apchenstu/TensoRF.git',\n    'gaussian-splatting': 'https://github.com/graphdeco-inria/gaussian-splatting.git',\n    'nerf-pytorch': 'https://github.com/yenchenlin/nerf-pytorch.git'\n}\n\nprint(\"克隆必要的代码仓库...\")\nfor name, url in repos.items():\n    if not os.path.exists(name):\n        subprocess.run(['git', 'clone', url], check=True)\n        print(f\"{name} 克隆完成\")\n    else:\n        print(f\"{name} 已存在\")\n# 安装依赖\nprint(\"\\n安装依赖...\")\nsubprocess.run(['pip', 'install', '-r', 'TensoRF/requirements.txt'], check=True)\nsubprocess.run(['pip', 'install', 'simple-knn/'], check=True)\n\nprint(\"\\n安装额外依赖...\")\nextra_deps = [\n    'configargparse',\n    'plyfile',\n    'tensorboard',\n    'opencv-python',\n    'pytorch3d',\n    'torch',\n    'torchvision',\n    'torchaudio'\n]\n\nfor dep in extra_deps:\n    try:\n        subprocess.run(['pip', 'install', dep], check=True)\n        print(f\"{dep} 安装成功\")\n    except subprocess.CalledProcessError as e:\n        print(f\"{dep} 安装失败: {e}\")\n\nprint(\"\\n环境初始化完成！\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T08:00:35.246728Z","iopub.execute_input":"2025-06-19T08:00:35.247259Z","iopub.status.idle":"2025-06-19T08:00:35.400249Z","shell.execute_reply.started":"2025-06-19T08:00:35.247235Z","shell.execute_reply":"2025-06-19T08:00:35.399472Z"}},"outputs":[{"name":"stdout","text":"开始下载 simple-knn...\n下载失败: HTTP Error 404: Not Found\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport subprocess\nfrom pathlib import Path\n\n# 创建必要的目录结构\ntensorf_third_party = Path('TensoRF/third_party')\nsimple_knn_dir = tensorf_third_party / 'simple-knn'\nos.makedirs(simple_knn_dir, exist_ok=True)\n\n# 创建 setup.py\nsetup_py = \"\"\"\nfrom setuptools import setup\nfrom torch.utils.cpp_extension import BuildExtension, CUDAExtension\nimport os\n\nsetup(\n    name='simple_knn',\n    ext_modules=[\n        CUDAExtension(\n            name='simple_knn.simple_knn_cuda',\n            sources=['simple_knn_cuda.cpp', 'simple_knn_cuda_kernel.cu'],\n            extra_compile_args={'cxx': ['-g'], 'nvcc': ['-O2']}\n        )\n    ],\n    packages=['simple_knn'],\n    cmdclass={'build_ext': BuildExtension}\n)\n\"\"\"\n\n# 创建 simple_knn_cuda.cpp\ncuda_cpp = \"\"\"\n#include <torch/extension.h>\n#include <vector>\n\ntorch::Tensor knn_forward_cuda(\n    torch::Tensor xyz1,\n    torch::Tensor xyz2,\n    const int K);\n\n#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n\ntorch::Tensor knn_forward(torch::Tensor xyz1, torch::Tensor xyz2, const int K) {\n    CHECK_INPUT(xyz1);\n    CHECK_INPUT(xyz2);\n    return knn_forward_cuda(xyz1, xyz2, K);\n}\n\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"knn_forward\", &knn_forward, \"KNN forward (CUDA)\");\n}\n\"\"\"\n\n# 创建 simple_knn_cuda_kernel.cu\ncuda_kernel = \"\"\"\n#include <torch/extension.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n\n__global__ void knn_kernel(\n    const float* __restrict__ xyz1,\n    const float* __restrict__ xyz2,\n    const int batch_size,\n    const int n,\n    const int m,\n    const int k,\n    int* __restrict__ idx) {\n    \n    const int batch = blockIdx.z;\n    const int pt_idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (pt_idx >= n) return;\n    \n    xyz1 += batch * n * 3 + pt_idx * 3;\n    xyz2 += batch * m * 3;\n    idx += batch * n * k + pt_idx * k;\n    \n    float x1 = xyz1[0];\n    float y1 = xyz1[1];\n    float z1 = xyz1[2];\n    \n    float best_dist[8];\n    int best_idx[8];\n    for (int i = 0; i < k; i++) {\n        best_dist[i] = 1e10;\n        best_idx[i] = 0;\n    }\n    \n    for (int i = 0; i < m; i++) {\n        float x2 = xyz2[i * 3 + 0];\n        float y2 = xyz2[i * 3 + 1];\n        float z2 = xyz2[i * 3 + 2];\n        float d = (x2 - x1) * (x2 - x1) + (y2 - y1) * (y2 - y1) + (z2 - z1) * (z2 - z1);\n        \n        for (int j = 0; j < k; j++) {\n            if (d < best_dist[j]) {\n                for (int l = k - 1; l > j; l--) {\n                    best_dist[l] = best_dist[l-1];\n                    best_idx[l] = best_idx[l-1];\n                }\n                best_dist[j] = d;\n                best_idx[j] = i;\n                break;\n            }\n        }\n    }\n    \n    for (int i = 0; i < k; i++) {\n        idx[i] = best_idx[i];\n    }\n}\n\ntorch::Tensor knn_forward_cuda(\n    torch::Tensor xyz1,\n    torch::Tensor xyz2,\n    const int K) {\n    \n    const int batch_size = xyz1.size(0);\n    const int n = xyz1.size(1);\n    const int m = xyz2.size(1);\n    \n    auto idx = torch::zeros({batch_size, n, K}, xyz1.options().dtype(torch::kInt32));\n    \n    const int threads = 256;\n    const dim3 blocks((n + threads - 1) / threads, 1, batch_size);\n    \n    knn_kernel<<<blocks, threads>>>(\n        xyz1.data_ptr<float>(),\n        xyz2.data_ptr<float>(),\n        batch_size, n, m, K,\n        idx.data_ptr<int>());\n    \n    return idx;\n}\n\"\"\"\n\n# 创建 __init__.py\ninit_py = \"\"\"\nfrom torch.utils.cpp_extension import load\nimport os\n\nsimple_knn_cuda = load(\n    name=\"simple_knn_cuda\",\n    sources=[\n        os.path.join(os.path.dirname(__file__), \"simple_knn_cuda.cpp\"),\n        os.path.join(os.path.dirname(__file__), \"simple_knn_cuda_kernel.cu\"),\n    ],\n)\n\n__all__ = [\"simple_knn_cuda\"]\n\"\"\"\n\ntry:\n    # 写入文件\n    os.makedirs(simple_knn_dir / 'simple_knn', exist_ok=True)\n    \n    with open(simple_knn_dir / 'setup.py', 'w') as f:\n        f.write(setup_py)\n    with open(simple_knn_dir / 'simple_knn_cuda.cpp', 'w') as f:\n        f.write(cuda_cpp)\n    with open(simple_knn_dir / 'simple_knn_cuda_kernel.cu', 'w') as f:\n        f.write(cuda_kernel)\n    with open(simple_knn_dir / 'simple_knn' / '__init__.py', 'w') as f:\n        f.write(init_py)\n        \n    print(\"源文件创建完成，开始安装...\")\n        # 安装 simple-knn\n    subprocess.run(['pip', 'install', str(simple_knn_dir)], check=True)\n    print(\"simple-knn 安装成功！\")\n    \nexcept Exception as e:\n    print(f\"安装过程中出错: {e}\")\n    print(\"\\n如果编译失败，可能需要：\")\n    print(\"1. 确保已安装 CUDA 工具包\")\n    print(\"2. 确保 PyTorch 版本与 CUDA 版本匹配\")\n    print(\"3. 检查是否有完整的编译工具链\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T08:13:32.603527Z","iopub.execute_input":"2025-06-19T08:13:32.604394Z","iopub.status.idle":"2025-06-19T08:14:44.796376Z","shell.execute_reply.started":"2025-06-19T08:13:32.604362Z","shell.execute_reply":"2025-06-19T08:14:44.795575Z"}},"outputs":[{"name":"stdout","text":"源文件创建完成，开始安装...\nProcessing ./TensoRF/third_party/simple-knn\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nBuilding wheels for collected packages: simple_knn\n  Building wheel for simple_knn (setup.py): started\n  Building wheel for simple_knn (setup.py): finished with status 'done'\n  Created wheel for simple_knn: filename=simple_knn-0.0.0-cp311-cp311-linux_x86_64.whl size=2635399 sha256=694ab251c09fd847341f4e2e2d52c270faa9f8ce1303f15c3527db4b7c3ad8ab\n  Stored in directory: /root/.cache/pip/wheels/aa/ed/17/f15d3ee7e9df3bdefb427667718dea085640e20456003ba50f\nSuccessfully built simple_knn\nInstalling collected packages: simple_knn\n  Attempting uninstall: simple_knn\n    Found existing installation: simple_knn 0.0.0\n    Uninstalling simple_knn-0.0.0:\n      Successfully uninstalled simple_knn-0.0.0\nSuccessfully installed simple_knn-0.0.0\nsimple-knn 安装成功！\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\nimport shutil\n\ninput_path = \"/kaggle/input\"","metadata":{"_uuid":"67a4fb98-018d-4974-b2e0-39ce5ef26e7b","_cell_guid":"72b3e1f5-1958-4c8d-b857-c6f3c07ec202","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:09:25.905503Z","iopub.execute_input":"2025-06-19T08:09:25.905777Z","iopub.status.idle":"2025-06-19T08:09:25.909648Z","shell.execute_reply.started":"2025-06-19T08:09:25.905757Z","shell.execute_reply":"2025-06-19T08:09:25.909116Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nimport shutil\n\ninput_path = \"/kaggle/input/my-object\"\noutput_path = \"/kaggle/working/output\"\n\n# 删除现有的输出目录\nif os.path.exists(output_path):\n    shutil.rmtree(output_path)\n\n# 复制目录\nshutil.copytree(input_path, output_path)","metadata":{"_uuid":"5d4b2731-b303-43ef-8379-8c12213ea0db","_cell_guid":"c9628a13-9c73-4a71-9bc9-b41838e20c30","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:09:28.015255Z","iopub.execute_input":"2025-06-19T08:09:28.015493Z","iopub.status.idle":"2025-06-19T08:09:34.486852Z","shell.execute_reply.started":"2025-06-19T08:09:28.015475Z","shell.execute_reply":"2025-06-19T08:09:34.486113Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/output'"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# 检查CUDA可用性\nimport torch\nprint(f\"CUDA is available: {torch.cuda.is_available()}\")\nprint(f\"CUDA device count: {torch.cuda.device_count()}\")\nif torch.cuda.is_available():\n    print(f\"Current CUDA device: {torch.cuda.get_device_name(0)}\")","metadata":{"_uuid":"3c692cb3-9b20-4d02-be6f-3d7bec2ab23a","_cell_guid":"a632f25f-7a6e-4abb-aacc-35b3ef8fc02e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:09:37.176038Z","iopub.execute_input":"2025-06-19T08:09:37.176770Z","iopub.status.idle":"2025-06-19T08:09:38.882009Z","shell.execute_reply.started":"2025-06-19T08:09:37.176741Z","shell.execute_reply":"2025-06-19T08:09:38.881215Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"CUDA is available: True\nCUDA device count: 2\nCurrent CUDA device: Tesla T4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"\n### 数据集结构\n```\nmy_object/\n    images/           # 拍摄的多角度图片\n    sparse/0/         # COLMAP输出\n        cameras.bin\n        images.bin\n        points3D.bin\n```","metadata":{"_uuid":"54e7bd57-19f6-4d99-937e-6fff791066bf","_cell_guid":"bbbc5f6f-aa96-448b-94d6-91fd6f58d918","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def create_transforms_json(data_dir: str):\n    \"\"\"\n    针对 my_object/ 结构，为训练集和测试集分别创建 transforms_train.json、transforms_test.json 文件，兼容TensoRF。\n    自动修正frames中file_path字段为相对images/的路径，避免路径拼接错误。\n    \"\"\"\n    import json\n    from pathlib import Path\n    data_path = Path(data_dir)\n    transforms_file = data_path / 'transforms.json'\n    if not transforms_file.exists():\n        raise FileNotFoundError(f\"找不到 {transforms_file}，请先运行 colmap2nerf.py 生成。\")\n    with open(transforms_file, 'r') as f:\n        transforms_data = json.load(f)\n    train_dir = data_path / 'train'\n    test_dir = data_path / 'test'\n    def get_stems(p):\n        return set(f.stem for f in p.glob('*') if f.is_file())\n    train_stems = get_stems(train_dir)\n    test_stems = get_stems(test_dir)\n    def filter_frames(stems):\n        # 修正file_path为 images/xxx.jpg 或 images/xxx.png\n        filtered = []\n        for frame in transforms_data['frames']:\n            stem = Path(frame['file_path']).stem\n            if stem in stems:\n                # 只保留 images/xxx.扩展名\n                ext = Path(frame['file_path']).suffix\n                frame['file_path'] = f\"images/{stem}{ext}\"\n                filtered.append(frame)\n        return filtered\n    train_frames = filter_frames(train_stems)\n    test_frames = filter_frames(test_stems)\n    # 写入TensoRF兼容的transforms_train.json、transforms_test.json\n    train_transforms = dict(transforms_data)\n    train_transforms['frames'] = train_frames\n    with open(data_path / 'transforms_train.json', 'w') as f:\n        json.dump(train_transforms, f, indent=2)\n    test_transforms = dict(transforms_data)\n    test_transforms['frames'] = test_frames\n    with open(data_path / 'transforms_test.json', 'w') as f:\n        json.dump(test_transforms, f, indent=2)\n    # 仍保留原有train/test目录下的transforms.json\n    with open(train_dir / 'transforms.json', 'w') as f:\n        json.dump(train_transforms, f, indent=2)\n    with open(test_dir / 'transforms.json', 'w') as f:\n        json.dump(test_transforms, f, indent=2)\n    print(f\"已为训练集({len(train_frames)})和测试集({len(test_frames)})生成 transforms_train.json / transforms_test.json 及各自目录下的transforms.json，图片路径已修正为 images/xxx.扩展名\")","metadata":{"_uuid":"e772eb72-baec-4c98-ab3a-81328f0de9af","_cell_guid":"e0adbcb8-1480-48b3-96b7-629c2dbdc59f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:10:05.233847Z","iopub.execute_input":"2025-06-19T08:10:05.234111Z","iopub.status.idle":"2025-06-19T08:10:05.242618Z","shell.execute_reply.started":"2025-06-19T08:10:05.234093Z","shell.execute_reply":"2025-06-19T08:10:05.241566Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport random\nimport shutil\nfrom pathlib import Path\nfrom PIL import Image\n\ndef split_dataset(data_dir: str, train_ratio: float = 0.8, seed: int = 42):\n    \"\"\"数据集划分为训练集和测试集\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    \n    data_path = Path(data_dir)\n    images_path = data_path / 'images'\n    train_dir = data_path / 'train'\n    test_dir = data_path / 'test'\n    train_dir.mkdir(exist_ok=True)\n    test_dir.mkdir(exist_ok=True)\n    \n    # 修复图片glob写法，分别匹配三种扩展名\n    image_files = []\n    for ext in ['jpg']:\n        image_files.extend(images_path.glob(f'*.{ext}'))\n    n_images = len(image_files)\n    n_train = int(n_images * train_ratio)\n    \n    random.shuffle(image_files)\n    train_files = image_files[:n_train]\n    test_files = image_files[n_train:]\n    \n    for f in train_files:\n        shutil.copy2(f, train_dir / f.name)\n    for f in test_files:\n        shutil.copy2(f, test_dir / f.name)\n    \n    print(f\"数据集划分完成：\")\n    print(f\"- 训练集：{len(train_files)}张图片\")\n    print(f\"- 测试集：{len(test_files)}张图片\")\n    \n    return train_dir, test_dir\n\ndef prepare_dataset(data_dir: str):\n    \"\"\"完整的数据准备流程\"\"\"\n    # 1. 运行COLMAP数据处理（修正参数为--images --text --out）\n    images_dir = os.path.join(data_dir, 'images')\n    colmap_text_dir = os.path.join(data_dir, 'colmap_text')\n    transforms_out = os.path.join(data_dir, 'transforms.json')\n    !python TensoRF/dataLoader/colmap2nerf.py --images {images_dir} --text {colmap_text_dir} --out {transforms_out}\n    \n    # 2. 划分数据集\n    train_dir, test_dir = split_dataset(data_dir)\n    \n    # 3. 创建transforms文件\n    create_transforms_json(data_dir)\n    \n    print(\"数据准备完成！\")","metadata":{"_uuid":"d51977eb-9673-4907-930d-8dd4b75e09a8","_cell_guid":"1b06ab10-d32b-4eab-9da7-dea5dff0d844","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:17:00.925514Z","iopub.execute_input":"2025-06-19T08:17:00.926218Z","iopub.status.idle":"2025-06-19T08:17:00.935381Z","shell.execute_reply.started":"2025-06-19T08:17:00.926197Z","shell.execute_reply":"2025-06-19T08:17:00.934682Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def visualize_camera_positions(transforms_json: str):\n    \"\"\"可视化相机位置分布\"\"\"\n    import matplotlib.pyplot as plt\n    from mpl_toolkits.mplot3d import Axes3D\n    \n    with open(transforms_json, 'r') as f:\n        data = json.load(f)\n    \n    positions = []\n    for frame in data['frames']:\n        transform = np.array(frame['transform_matrix'])\n        position = transform[:3, 3]\n        positions.append(position)\n    \n    positions = np.array(positions)\n    \n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2])\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n    ax.set_title('Camera Positions')\n    plt.show()","metadata":{"_uuid":"bade8857-c502-46b2-9875-53e57d7c4725","_cell_guid":"bdb654de-1435-4d04-bebb-c5641155c56b","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-06-19T08:26:23.786Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n包含三种模型的训练和渲染实现。","metadata":{"_uuid":"4acd3f63-3e5f-432f-a3d4-46009e58b436","_cell_guid":"0d32a8e9-2bea-488d-80d0-f88f6dd417b8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# TensoRF配置\ndef create_tensorf_config(data_dir, exp_name):\n    \"\"\"创建TensoRF训练配置，并将配置文件写入TensoRF目录下\"\"\"\n    config = {\n        'dataset_name': 'own_data',\n        'datadir': data_dir,\n        'expname': exp_name,\n        'basedir': './log',\n        'n_iters': 30000,\n        'batch_size': 4096,\n        'N_voxel_init': 2097156,  # 128**3\n        'N_voxel_final': 27000000,  # 300**3\n        'upsamp_list': [2000, 3000, 4000, 5500, 7000],\n        'update_AlphaMask_list': [2000, 4000],\n        'model_name': 'TensorVMSplit',\n        'n_lamb_sigma': [16, 16, 16],\n        'n_lamb_sh': [48, 48, 48]\n    }\n    config_path = os.path.join('TensoRF', 'tensorf_config.txt')\n    with open(config_path, 'w') as f:\n        for key, value in config.items():\n            f.write(f\"{key} = {value}\\n\")\n    return config_path\n\ndef train_models(data_dir: str):\n    \"\"\"训练三个模型\"\"\"\n    # 1. TensoRF\n    config_path = create_tensorf_config(data_dir, 'experiment_1')\n    !cd TensoRF && python train.py --config tensorf_config.txt\n    \n    # 2. Original NeRF（只传递NeRF需要的参数）\n    !cd nerf && python run_nerf.py --config configs/default.txt --datadir {data_dir}\n    \n    # 3. 3D Gaussian Splatting\n    !cd gaussian-splatting && python train.py -s {data_dir}","metadata":{"_uuid":"7f66143a-f835-4535-b470-ca06d13a4cc9","_cell_guid":"c95efc01-edf5-479c-84e5-213c03a5ab8a","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-06-19T08:26:23.786Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n使用Tensorboard监控训练过程，包括：\n- 训练集和测试集上的loss曲线\n- PSNR指标变化\n- SSIM指标变化","metadata":{"_uuid":"56450cd4-7379-4d2b-ac1f-c7439d0ef18e","_cell_guid":"35f3970f-0f3a-40f3-a75c-2bb92fe1b2ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nimport datetime\n\ndef setup_tensorboard(experiment_name):\n    \"\"\"设置Tensorboard\"\"\"\n    current_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n    log_dir = f'runs/{experiment_name}_{current_time}'\n    return SummaryWriter(log_dir)\n\ndef log_metrics(writer, metrics, step):\n    \"\"\"记录训练指标\"\"\"\n    for key, value in metrics.items():\n        writer.add_scalar(key, value, step)","metadata":{"_uuid":"47b7fc43-600b-45b3-9442-0c8a716ee56c","_cell_guid":"d541ef22-a9e5-4d57-b671-e968b2e102a4","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-06-19T08:26:23.786Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 创建环绕相机轨迹\ndef create_circular_trajectory(n_frames=120, radius=4.0, height=0.0):\n    \"\"\"创建环绕物体的圆形相机轨迹\"\"\"\n    trajectory = []\n    for i in range(n_frames):\n        angle = (i / n_frames) * 2 * np.pi\n        x = radius * np.cos(angle)\n        z = radius * np.sin(angle)\n        y = height\n        \n        look_at = np.array([0, 0, 0])\n        pos = np.array([x, y, z])\n        up = np.array([0, 1, 0])\n        \n        forward = look_at - pos\n        forward = forward / np.linalg.norm(forward)\n        right = np.cross(forward, up)\n        right = right / np.linalg.norm(right)\n        up = np.cross(right, forward)\n        \n        c2w = np.eye(4)\n        c2w[:3, :3] = np.stack([right, up, -forward], axis=1)\n        c2w[:3, 3] = pos\n        \n        trajectory.append(c2w.tolist())\n    \n    return trajectory","metadata":{"_uuid":"aceeb7ea-4f65-438a-afa9-09438c7b4b8c","_cell_guid":"c338c8fa-9ccb-4852-b8ae-6f1aea5ecdc1","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-06-19T08:26:23.786Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from dataclasses import dataclass\n\n@dataclass\nclass ModelPerformance:\n    \"\"\"记录模型性能指标\"\"\"\n    name: str\n    training_time: float\n    inference_time: float\n    psnr: float\n    ssim: float\n    memory_usage: float\n    parameters: int\n\ndef evaluate_models(data_dir: str):\n    \"\"\"评估三个模型的性能\"\"\"\n    # 创建环绕轨迹\n    trajectory = create_circular_trajectory()\n    \n    # 评估每个模型\n    models = ['nerf', 'tensorf', 'gaussian']\n    results = {}\n    \n    for model in models:\n        if model == 'tensorf':\n            metrics = evaluate_on_test_set('tensorf', 'tensorf_config.txt', 'TensoRF/logs/model.pth')\n        elif model == 'nerf':\n            metrics = evaluate_on_test_set('nerf', 'nerf/configs/default.txt', 'nerf/logs/model.pth')\n        else:\n            metrics = evaluate_on_test_set('gaussian', ckpt_path='gaussian_model.ply')\n        \n        results[model] = metrics\n    \n    return results","metadata":{"_uuid":"a694b2e6-d187-433b-a5a3-50762bd66202","_cell_guid":"67927cdb-c27a-481c-b8b8-bfc8d2471b03","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-06-19T08:26:23.787Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n比较三种方法的:\n1. 训练时间和效率\n2. 渲染质量（PSNR/SSIM）\n3. 资源消耗","metadata":{"_uuid":"081e5240-0210-4894-b91c-701a7ff0bd02","_cell_guid":"11c79541-77bb-4ac5-9494-92be4045677e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def visualize_results(results):\n    \"\"\"可视化对比结果\"\"\"\n    import matplotlib.pyplot as plt\n    \n    metrics = ['psnr', 'ssim', 'training_time', 'inference_time']\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    fig.suptitle('Model Performance Comparison')\n    \n    for (metric, ax) in zip(metrics, axes.flat):\n        values = [results[model][metric] for model in results]\n        ax.bar(['NeRF', 'TensoRF', 'Gaussian'], values)\n        ax.set_title(metric.upper())\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"_uuid":"fe414833-609b-4618-840a-3567b6f0484a","_cell_guid":"1b90f824-5930-429a-a688-5febf590e4dd","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-06-19T08:26:23.787Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n```python\n# 1. 准备数据\ndata_dir = 'data/my_object'\nprepare_dataset(data_dir)\n\n# 2. 训练模型\ntrain_models(data_dir)\n\n# 3. 评估结果\nresults = evaluate_models(data_dir)\nvisualize_results(results)\n```","metadata":{"_uuid":"1d308e7f-db4e-4755-868b-b15664bb8b4d","_cell_guid":"145f749c-f846-49f2-90ce-c0167560a76c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 复制TensoRF的配置模板为NeRF默认配置，解决缺省配置文件报错\nimport shutil, os\nnerf_config_dir = os.path.join('nerf', 'configs')\nos.makedirs(nerf_config_dir, exist_ok=True)\nshutil.copy(os.path.join('TensoRF', 'configs', 'your_own_data.txt'), os.path.join(nerf_config_dir, 'default.txt'))\nprint('已复制TensoRF/configs/your_own_data.txt 到 nerf/configs/default.txt')","metadata":{"_uuid":"a5deb4e5-298f-441c-bca4-7127a0835163","_cell_guid":"e5572d19-cc81-4b16-85b1-8ae6a21a582d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:17:14.901211Z","iopub.execute_input":"2025-06-19T08:17:14.901809Z","iopub.status.idle":"2025-06-19T08:17:14.907312Z","shell.execute_reply.started":"2025-06-19T08:17:14.901786Z","shell.execute_reply":"2025-06-19T08:17:14.906589Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"已复制TensoRF/configs/your_own_data.txt 到 nerf/configs/default.txt\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 1. 准备数据\ndata_dir = '/kaggle/working/output/my_object'\nprepare_dataset(data_dir)","metadata":{"_uuid":"16fc379a-3ab6-4b51-865a-0f3bb5873c14","_cell_guid":"541e58b3-486b-4265-8c8e-982d16ea5e57","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:17:16.768531Z","iopub.execute_input":"2025-06-19T08:17:16.768848Z","iopub.status.idle":"2025-06-19T08:17:46.606263Z","shell.execute_reply.started":"2025-06-19T08:17:16.768807Z","shell.execute_reply":"2025-06-19T08:17:46.605391Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"outputting to /kaggle/working/output/my_object/transforms.json...\ncamera:\n\tres=(4032.0, 3024.0)\n\tcenter=(2016.0, 1512.0)\n\tfocal=(3103.4958727628095, 3103.4958727628095)\n\tfov=(66.01470378899995, 51.949995644430814)\n\tk=(0, 0) p=(0, 0) \n./output/my_object/images/1.jpg sharpness= 13.536895517108938\n./output/my_object/images/10.jpg sharpness= 109.25318959526804\n./output/my_object/images/11.jpg sharpness= 99.98418496873414\n./output/my_object/images/12.jpg sharpness= 103.55315322935502\n./output/my_object/images/13.jpg sharpness= 103.63760479992881\n./output/my_object/images/14.jpg sharpness= 102.46960480946849\n./output/my_object/images/15.jpg sharpness= 7.543972817391103\n./output/my_object/images/16.jpg sharpness= 21.02232539157227\n./output/my_object/images/18.jpg sharpness= 12.513672702113338\n./output/my_object/images/19.jpg sharpness= 13.875606778228201\n./output/my_object/images/2.jpg sharpness= 104.55573048752075\n./output/my_object/images/20.jpg sharpness= 114.3403258061419\n./output/my_object/images/21.jpg sharpness= 118.10334905084524\n./output/my_object/images/22.jpg sharpness= 14.05642436698217\n./output/my_object/images/23.jpg sharpness= 13.217219444636825\n./output/my_object/images/24.jpg sharpness= 13.474438588844263\n./output/my_object/images/25.jpg sharpness= 14.310541495956661\n./output/my_object/images/26.jpg sharpness= 14.787190119911338\n./output/my_object/images/27.jpg sharpness= 14.055432261101018\n./output/my_object/images/28.jpg sharpness= 12.2415300674457\n./output/my_object/images/29.jpg sharpness= 11.30380424207705\n./output/my_object/images/3.jpg sharpness= 11.037578961322811\n./output/my_object/images/30.jpg sharpness= 18.9485096723625\n./output/my_object/images/31.jpg sharpness= 15.32193158891093\n./output/my_object/images/32.jpg sharpness= 133.86177584887517\n./output/my_object/images/33.jpg sharpness= 126.11009099757499\n./output/my_object/images/34.jpg sharpness= 130.05493116861018\n./output/my_object/images/35.jpg sharpness= 124.59634169054175\n./output/my_object/images/36.jpg sharpness= 155.6222758432165\n./output/my_object/images/37.jpg sharpness= 12.075636952293857\n./output/my_object/images/38.jpg sharpness= 13.269541721693814\n./output/my_object/images/39.jpg sharpness= 13.69339582215997\n./output/my_object/images/4.jpg sharpness= 92.93178685759183\n./output/my_object/images/40.jpg sharpness= 12.854677123653804\n./output/my_object/images/41.jpg sharpness= 16.54083435307258\n./output/my_object/images/42.jpg sharpness= 25.72819537734603\n./output/my_object/images/43.jpg sharpness= 20.735931360276314\n./output/my_object/images/44.jpg sharpness= 19.78151192100367\n./output/my_object/images/45.jpg sharpness= 13.926388135636385\n./output/my_object/images/46.jpg sharpness= 15.917359683198065\n./output/my_object/images/47.jpg sharpness= 13.711346497259987\n./output/my_object/images/48.jpg sharpness= 25.72511177921837\n./output/my_object/images/49.jpg sharpness= 23.567172831610847\n./output/my_object/images/5.jpg sharpness= 92.6657129044692\n./output/my_object/images/50.jpg sharpness= 27.575424788966508\n./output/my_object/images/51.jpg sharpness= 21.26007590293109\n./output/my_object/images/52.jpg sharpness= 23.950605339117434\n./output/my_object/images/53.jpg sharpness= 19.51307080538896\n./output/my_object/images/54.jpg sharpness= 18.154498117602905\n./output/my_object/images/55.jpg sharpness= 31.921977992303212\n./output/my_object/images/56.jpg sharpness= 16.615166241443546\n./output/my_object/images/57.jpg sharpness= 14.883409286915096\n./output/my_object/images/58.jpg sharpness= 14.191137126961388\n./output/my_object/images/59.jpg sharpness= 14.223960662686292\n./output/my_object/images/6.jpg sharpness= 94.33059267432014\n./output/my_object/images/60.jpg sharpness= 12.10553428759155\n./output/my_object/images/61.jpg sharpness= 13.067619327040733\n./output/my_object/images/62.jpg sharpness= 11.900019239167957\n./output/my_object/images/63.jpg sharpness= 15.084864542014023\n./output/my_object/images/64.jpg sharpness= 19.456999996736812\n./output/my_object/images/65.jpg sharpness= 11.645156510237173\n./output/my_object/images/66.jpg sharpness= 10.369276836125715\n./output/my_object/images/67.jpg sharpness= 9.85222953560359\n./output/my_object/images/68.jpg sharpness= 10.722381884828946\n./output/my_object/images/69.jpg sharpness= 10.448672769184094\n./output/my_object/images/7.jpg sharpness= 104.96954768578269\n./output/my_object/images/70.jpg sharpness= 10.708487479405228\n./output/my_object/images/71.jpg sharpness= 10.391735492770511\n./output/my_object/images/72.jpg sharpness= 10.537796735151971\n./output/my_object/images/73.jpg sharpness= 15.863189512475552\n./output/my_object/images/74.jpg sharpness= 10.641706028419048\n./output/my_object/images/75.jpg sharpness= 10.829092949018412\n./output/my_object/images/78.jpg sharpness= 53.47365026417511\n./output/my_object/images/79.jpg sharpness= 58.61249783449661\n./output/my_object/images/8.jpg sharpness= 40.887358219574054\n./output/my_object/images/80.jpg sharpness= 59.52523167831938\n./output/my_object/images/9.jpg sharpness= 102.1845554642628\nup vector was [-0.8575944  -0.14608213 -0.49314486]\ncomputing center of attention...\n[-3.7289925  -0.57090093  0.86818538]\navg camera distance from origin 5.132975444015476\n77 frames\nwriting /kaggle/working/output/my_object/transforms.json\n数据集划分完成：\n- 训练集：64张图片\n- 测试集：16张图片\n已为训练集(61)和测试集(16)生成 transforms_train.json / transforms_test.json 及各自目录下的transforms.json，图片路径已修正为 images/xxx.扩展名\n数据准备完成！\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# 安装TensoRF/NeRF依赖\n!pip install configargparse plyfile\n\n# 编译并安装Gaussian Splatting的diff-gaussian-rasterization子模块\nimport os\nos.chdir('gaussian-splatting/submodules/diff-gaussian-rasterization')\nif os.path.exists('setup.py') or os.path.exists('pyproject.toml'):\n    # 使用pip安装当前目录\n    !pip install .\nelse:\n    print(\"未找到setup.py或pyproject.toml，请检查子模块是否完整。\")\nos.chdir('../simple-knn')\nif os.path.exists('setup.py') or os.path.exists('pyproject.toml'):\n    # 使用pip安装当前目录\n    !pip install .\nelse:\n    print(\"未找到setup.py或pyproject.toml，请检查simple-knn子模块是否完整。\")\nos.chdir('../../../')","metadata":{"_uuid":"bb3b0515-976f-4ecd-afb6-ab7352e40e41","_cell_guid":"22cca51b-acd6-4d69-8a07-f7a26eeb62f2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:18:11.544136Z","iopub.execute_input":"2025-06-19T08:18:11.544443Z","iopub.status.idle":"2025-06-19T08:18:14.643643Z","shell.execute_reply.started":"2025-06-19T08:18:11.544417Z","shell.execute_reply":"2025-06-19T08:18:14.642877Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: configargparse in /usr/local/lib/python3.11/dist-packages (1.7.1)\nRequirement already satisfied: plyfile in /usr/local/lib/python3.11/dist-packages (1.1.2)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from plyfile) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->plyfile) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->plyfile) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->plyfile) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->plyfile) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->plyfile) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->plyfile) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->plyfile) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->plyfile) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->plyfile) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->plyfile) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->plyfile) (2024.2.0)\n未找到setup.py或pyproject.toml，请检查子模块是否完整。\n未找到setup.py或pyproject.toml，请检查simple-knn子模块是否完整。\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# 2. 训练模型\ntrain_models(data_dir)","metadata":{"_uuid":"d186dfe2-02bc-4b0b-8c36-2f841ebe84b3","_cell_guid":"654ab0e1-f203-4087-a491-609f941eeb33","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-19T08:19:36.985006Z","iopub.execute_input":"2025-06-19T08:19:36.985736Z","iopub.status.idle":"2025-06-19T08:20:23.406493Z","shell.execute_reply.started":"2025-06-19T08:19:36.985713Z","shell.execute_reply":"2025-06-19T08:20:23.405515Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"2025-06-19 08:19:57.768411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750321198.298273     268 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750321198.432344     268 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nNamespace(config='tensorf_config.txt', expname='experiment_1', basedir='./log', add_timestamp=0, datadir='/kaggle/working/output/my_object', progress_refresh_rate=10, with_depth=False, downsample_train=1.0, downsample_test=1.0, model_name='TensorVMSplit', batch_size=4096, n_iters=30000, dataset_name='own_data', lr_init=0.02, lr_basis=0.001, lr_decay_iters=-1, lr_decay_target_ratio=0.1, lr_upsample_reset=1, L1_weight_inital=0.0, L1_weight_rest=0, Ortho_weight=0.0, TV_weight_density=0.0, TV_weight_app=0.0, n_lamb_sigma=[16, 16, 16], n_lamb_sh=[48, 48, 48], data_dim_color=27, rm_weight_mask_thre=0.0001, alpha_mask_thre=0.0001, distance_scale=25, density_shift=-10, shadingMode='MLP_PE', pos_pe=6, view_pe=6, fea_pe=6, featureC=128, ckpt=None, render_only=0, render_test=0, render_train=0, render_path=0, export_mesh=0, lindisp=False, perturb=1.0, accumulate_decay=0.998, fea2denseAct='softplus', ndc_ray=0, nSamples=1000000.0, step_ratio=0.5, white_bkgd=False, N_voxel_init=2097156, N_voxel_final=27000000, upsamp_list=[2000, 3000, 4000, 5500, 7000], update_AlphaMask_list=[2000, 4000], idx_view=0, N_vis=5, vis_every=10000)\nLoading data train (61):   0%|                           | 0/61 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/kaggle/working/TensoRF/train.py\", line 317, in <module>\n    reconstruction(args)\n  File \"/kaggle/working/TensoRF/train.py\", line 93, in reconstruction\n    train_dataset = dataset(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/TensoRF/dataLoader/your_own_data.py\", line 25, in __init__\n    self.read_meta()\n  File \"/kaggle/working/TensoRF/dataLoader/your_own_data.py\", line 75, in read_meta\n    img = Image.open(image_path)\n          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3465, in open\n    fp = builtins.open(filename, \"rb\")\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/kaggle/working/output/my_object/images/1.jpg.png'\npython3: can't open file '/kaggle/working/nerf/run_nerf.py': [Errno 2] No such file or directory\nTraceback (most recent call last):\n  File \"/kaggle/working/gaussian-splatting/train.py\", line 16, in <module>\n    from gaussian_renderer import render, network_gui\n  File \"/kaggle/working/gaussian-splatting/gaussian_renderer/__init__.py\", line 14, in <module>\n    from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer\nModuleNotFoundError: No module named 'diff_gaussian_rasterization'\n","output_type":"stream"}],"execution_count":23}]}